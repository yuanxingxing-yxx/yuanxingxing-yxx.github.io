[{"title":"Ubuntu下搭建HBase的单机模式以及伪分布式模式","date":"2020-05-07T16:01:12.000Z","path":"2020/05/08/Ubuntu下搭建HBase的单机模式以及伪分布式模式/","text":"HBase环境的安装HBase压缩文件解压将下载文件夹中的HBase压缩文件解压(可选,Windows与ubuntu的文件共享可参考上一篇文章：Ubuntu下搭建Hadoop的单机模式以及伪分布式模式) 1sudo tar -xzvf ~/下载/hbase-2.2.0-bin.tar.gz 为了方便使用将hbase解压后的文件更名。 文件授予权限为文件授予权限，避免遇到文件无法创建等问题，注意更改为当前用户名 1sudo chown -R hadoop ./hbase HBase单机模式配置修改hbase-env.sh配置文件修改conf文件夹中hbase-env.sh配置文件 1gedit hbase-env.sh 因为hbase是基于Zookeeper进行协调管理，则删除下图中的‘#’删除此处‘#’，并查看java目录下的jdk版本 修改hbase-site.xml配置文件修改conf文件夹中hbase-site.xml配置文件 1gedit hbase-site.xml 验证HBase版本号切换到bin目录下，验证hbase版本号 1./hbase version 启动HBase数据库系统bin目录下，启动HBase数据库系统 1./start-hbase.sh jps查看进程jps查看进程，检查hbase是否启动，若包括HMaster则启动成功 1jps 启动HBase命令行模式启动HBase数据库命令行模式 1./hbase shell 启动成功标志如下 查看HBase命令行模式下的进程此时，打开另一个终端查看进程，main代表启动hbase终端，即可进行创建表等基本操作 关闭HBase命令行模式关闭HBase数据库命令行模式 1quit 关闭hbase数据库1./stop-hbase.sh HBase伪分布式配置配置hbase-env.sh文件修改conf目录下的hbase-env.sh文件使用gedit编辑器打开/usr/local/hbase/conf/hbase-env.sh，命令如下： 1gedit /usr/local/hbase/conf/hbase-env.sh 修改配置文件如下三处后保存 配置hbase-site.xml文件修改conf文件夹中hbase-site.xml配置文件 1gedit /usr/local/hbase/conf/hbase-site.xml 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 启动运行HBase首先登陆ssh，由于搭建hadoop时已经设置了无密码登陆，因此这里不需要密码，然后切换到/usr/local/hadoop目录下，启动Hadoop，让HDFS进入运行状态，从而可以为HBase存储数据，具体命令如下： 123ssh localhostcd /usr/local/hadoop./sbin/start-dfs.sh 输入命令jps，如果能看到NameNode，DataNode，SecondNode这三个进程，则表示已经成功启动Hadoop然后启动HBase，命令如下 12cd /usr/local/hbase/bin./start-hbase.sh 启动HBase Shell模式进入HBase Shell模式，命令如下： 1./hbase shell 关闭HBase Shell模式1quit 关闭HBase在/usr/local/hbase/bin目录下，可以使用如下命令停止HBase运行： 1./stop-hbase.sh 12cd /usr/local/hadoop./sbin/stop-dfs.sh 如果在操作HBase的过程中发生错误，可以查看{HBASE_HOME}目录(即/usr/local/hbase)下的logs子目录中的日志文件，来寻找可能的错误原因。 最后需要注意的是，启动关闭Hadoop和HBase的顺序一定是：启动Hadoop-&gt;启动HBase-&gt;关闭HBase-&gt;关闭Hadoop。 Ubuntu下搭建HBase的单机模式以及伪分布式模式到此就结束了。小编经过疯狂的踩坑，熟悉了linux操作系统的部分命令。各位可爱们在搭建过程中一定要注意细节哦，如果博客中有问题，欢迎各位大神们指点迷津。","tags":[]},{"title":"Ubuntu下搭建Hadoop的单机模式以及伪分布式模式","date":"2020-04-24T11:20:21.000Z","path":"2020/04/24/Ubuntu下搭建Hadoop的单机模式以及伪分布式模式/","text":"环境准备创建Hadoop用户(可选)1.如果安装 Ubuntu 的时候不是用的 “hadoop” 用户，那么需要增加一个名为hadoop 的用户，首先按打开终端窗口（快捷键ctrl+alt+t），输入如下命令创建新用户 :创建hadoop用户。 1sudo useradd –m hadoop –s /bin/bash 2.上面这条命令创建了可以登陆的 hadoop 用户，并使用 /bin/bash 作为 shell 接着使用如下命令设置密码，可简单设置为 hadoop，按提示输入两次密码: 1sudo passwd hadoop 3.可为 hadoop 用户增加管理员权限，方便部署，避免一些对新手来说比较棘 手的权限问题: 1sudo adduser hadoop sudo SSH登录权限设置1.SSH简介SSH 为 Secure Shell 的缩写，是建立在应用层和传输层基础上的安全协议。 SSH 是目前较可靠、专为远程登录会话和其他网络服务提供安全性的协议。 利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH最初是 UNIX系统上的一个程序，后来又迅速扩展到其他操作平台。 SSH是由客 户端和服务端的软件组成，服务端是一个守护进程(daemon)，它在后台运 行并响应来自客户端的连接请求，客户端包含ssh程序以及像scp(远程拷 贝)、slogin(远程登陆)、sftp(安全文件传输)等其他的应用程序。2. 配置SSH的原因Hadoop名称节点(NameNode)需要启动集群中所有机器的Hadoop守护进程，这个过 程需要通过SSH登录来实现。Hadoop并没有提供SSH输入密码登录的形式，因此，为 了能够顺利登录每台机器，需要将所有机器配置为名称节点可以无密码登录它们。3. 切换登录用户以hadoop登录（可选）4. 更新（可选） 1sudo apt-get update 5.（1） 配置SSH的无密码登录安装openssh-server( 通常Linux系统会默认安装openssh的客户端软件openssh-client)，所以需要自己安装一下服务端。 1sudo apt-get install openssh-server （2）输入 cd .ssh目录下，如果没有.ssh文件 输入 ssh localhost生成 1cd ~/.ssh/ （3）生成秘钥 1ssh-keygen -t rsa （4）将Master中生成的密钥加入授权（authorized_keys） 1cat id_rsa.pub # 查看生成的公钥 12cat id_rsa.pub &gt;&gt; authorized_keys # 加入授权chmod 600 authorized_keys # 修改文件权限，如果不修改文件权限那么其它用户就能查看该授权 （5）完成后，直接键入“ssh localhost”，能无密码登录即可（6）键入“exit”退出，到此SSH无密码登录配置就成功了 安装Java环境1.Windows与Ubuntu数据共享（可将Windows下的文件进行共享，可选）（1）Windows系统操作（2）Ubuntu系统操作（基于VirtualBox）点击设备-&gt;安装增强功能输入密码后直接回车再次点击设备-&gt;共享文件夹-&gt;共享文件夹桌面会增加两个盘，点击sf_盘输入密码，即可将改文件夹中的内容复制到ubuntu下（小编复制到了下载文件夹中） 移动完成后，即可删除两个盘 2.在Ubuntu将jdk移动到我们新建的java目录下（没建的新建一个就是），到此传输文件成功，可以开始配置Java环境了。 1sudo mkdir java 注意根据自己的jdk版本号以及当前用户名执行 1sudo mv /home/hadoop/下载/jdk-8u221-linux-x64.tar.gz usr/java 在java目录中，使用sudo tar命令解压jdk文件，解压成功后，java目录中会有对应的目录文件存在 1sudo tar -zxvf jdk-8u221-linux-x64.tar.gz 3.配置java环境（1） 使用命令“sudo gedit ~/.bashrc”打开配置文件，在末尾添加以下几行文字，注意自己的jdk版本号。 12345 #set java envexport JAVA_HOME=/usr/lib/jdk/jdk1.8.0_221export JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH（2）使用命令“source ~/.bashrc”使环境变量生效（关闭配置文件并在当前目录即/usr/java目录下执行）。 1source ~/.bashrc （3）配置软连接，软连接相当于windows系统中的快捷键，部分软件可能会从/usr/bin目录下查找Java，因此添加该软连接防止其他软件查找不到的情况。 1sudo update-alternatives --install /usr/bin/java java /usr/java/jdk1.8.0_221/bin/java 300 1sudo update-alternatives --install /usr/bin/javac javac /usr/java/jdk1.8.0_221/bin/javac 300 （4）测试java是否安装成功 1java -version 单机模式以及伪分布式模式的搭建Hadoop单机安装配置1.将我们下载的Hadoop解压到 /usr/local/ 中（与解压jdk类似） 1sudo tar zxvf /home/hadoop/下载/hadoop-3.2.1.tar.gz -C /usr/local 2.利用cd /usr/local/ 命令切换操作空间，将文件夹名改为hadoop 1sudo mv ./hadoop-3.2.1/ ./hadoop 3.修改文件权限 1sudo chown -R hadoop:hadoop ./hadoop 1sudo chown -R 当前用户名 /usr/local/hadoop 4.修改配置文件Hadoop 解压后，在hadoop目录下的etc/hadoop/hadoop-env.sh文件中添加如下的 Java环境信息（可加到文本末尾，注意jdk版本号） 1export JAVA_HOME=/usr/java/jdk1.8.0_221 5.然后，保存hadoop-env.sh文件，即完成单机模式的Hadoop基本安装。测试Hadoop是否安装成功，如出现如下图所示的版本信息，即可。 1./bin/hadoop/ version 6.默认情况下，单机模式的Hadoop以Java进程的方式运行，可依次运行如下命令进行进一步测试。 12sudo mkdir inputsudo cp etc/hadoop/*.xml input 7.执行下列命令，运行MapReduce程序，完成测试计算。 1bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output &#x27;dfs[a-z.]+&#x27; 8. 执行下列命令，查看计算结果。 1cat output/* hadoop目录下，会有input和output两个新建的文件，output中有上述程序 的运算结果，到此hadoop单机安装配置成功。 Hadoop伪分布式安装配置1.Hadoop伪分布式安装配置（1）Hadoop可以在单节点上以伪分布式的方式运行，Hadoop进程以分 离的 Java 进程来运行，节点既作为 NameNode 也作为 DataNode， 同时，读取的是 HDFS 中的文件（2）Hadoop的配置文件位于/usr/local/hadoop/etc/hadoop/中，伪分布式 需要修改2个配置文件 core-site.xml 和 hdfs-site.xml（3）Hadoop的配置文件是xml格式，每个配置以声明property的name 和 value 的方式来实现hadoop目录认识2.hadoop下的目录（1）修改配置文件之前，先看一下hadoop下的目录：bin：hadoop最基本的管理脚本和使用脚本所在目录，这些脚本是sbin目录下管理脚本的基础实现，用户可以直接使用这些脚本管理和使用hadoop（2）etc：配置文件存放的目录，包括core-site.xml,hdfs-site.xml,mapred-site.xml等从hadoop1.x继承而来的配置文件和yarn-site.xml等hadoop2.x新增的配置文件（3）include：对外提供的编程库头文件（具体动态库和静态库在lib目录中，这些头文件军事用c++定义的，通常用于c++程序访问hdfs或者编写mapreduce程序）（4）Lib：该目录包含了hadoop对外提供的才变成动态库和静态库，与include目录中的头文件结合使用（5）libexec：各个服务对应的shell配置文件所在目录，可用于配置日志输出目录、启动参数等信息（6）sbin：hadoop管理脚本所在目录，主要包含hdfs和yarn中各类服务的启动、关闭脚本（7）share：hadoop各个模块编译后的jar包所在目录。3. 修改配置文件 core-site.xml 1234567891011 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; （1）hadoop.tmp.dir表示存放临时数据的目录，即包括NameNode的数据，也包 括DataNode的数据。该路径任意指定，只要实际存在该文件夹即可（2）name为fs.defaultFS的值，表示hdfs路径的逻辑名称 4.修改配置文件 hdfs-site.xml 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; （1）dfs.replication表示副本的数量，伪分布式要设置为1（2）dfs.namenode.name.dir表示本地磁盘目录，是存储fsimage文件的地方（3）dfs.datanode.data.dir表示本地磁盘目录，HDFS数据存放block的地方 5.至此，配置完毕，但是还不能启动，要对hdfs先进行格式化。类似以前的软盘，使用前要先格式化,执行如下命令，看到日志信息，即格式化成功。 1sudo ./bin/hdfs namenode -format 6.在我们name目录(这个目录是我们自己配置的时候指定的)下也会出现映像文件（fsimage），用于将数据持久化 。7.启动hadoop 1sbin/start-dfs.sh 8.安装jps 1sudo apt install openjdk-11-jdk-headless 9.安装好之后jps检查角色如果有多个角色，就启动成功。 1jps 10.浏览器访问localhost:9870 11.关闭hadoop（使用完毕后一定要关闭，否则相当容易崩） 1./sbin/stop-dfs.sh Ubuntu下搭建Hadoop的单机模式以及伪分布式模式到此就结束了。小编经过疯狂的踩坑，熟悉了linux操作系统的部分命令。各位可爱们在搭建过程中一定要注意细节哦，配置文件这些可以不用自己手敲，通过复制代码，保存在文本文件中，再利用Windows和Ubuntu数据共享，很快就可以节省时间啦。最后，如果博客中有问题，希望各位大神们指点迷津。","tags":[]}]